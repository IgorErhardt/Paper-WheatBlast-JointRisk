{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Importation ----------------------------------------\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob as gl\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definitions --------------------------------------\n",
    "def CalculateGDD(Temp, TempBase):\n",
    "    return np.where((Temp >= 0) & (Temp <= 40), np.maximum(Temp - TempBase, 0), 0)\n",
    "\n",
    "def CalculateAccumulatedGDD(WheaterDataset, SowingDate, EndDate, OutputFolder):    \n",
    "    TmeanDataset = WheaterDataset['Tmean'] # Get Mean Temperature Dataset\n",
    "    TmeanDataset_MeanCycle = TmeanDataset.sel(time=slice(SowingDate, EndDate)).mean(dim='time', skipna=True)\n",
    "    DateIndex = np.where(TmeanDataset['time'] == np.datetime64(SowingDate))[0][0] # Get Sowing Date Time Index\n",
    "    EndIndex = np.where(TmeanDataset['time'] == np.datetime64(EndDate))[0][0] # Heading Date Time Index\n",
    "    AccumulatedGDD = xr.zeros_like(TmeanDataset.isel(time=0)) # Initialize Empty Array To Store AccumulatedGDD\n",
    "\n",
    "    TempBase = 0\n",
    "    \n",
    "    for i in range(DateIndex, EndIndex):\n",
    "        TmeanData = TmeanDataset.isel(time=i) # Get Mean Temperature DataArray According to Date\n",
    "        gdd = CalculateGDD(TmeanData, TempBase) # Calculate GDD Array\n",
    "        AccumulatedGDD = AccumulatedGDD + gdd # Update AccumulatedGDD Array\n",
    "\n",
    "    YearInfo = pd.to_datetime(TmeanData['time'].values).year # Store Year Information\n",
    "    OutputDataset = xr.Dataset(\n",
    "        {'AccumulatedGDD': AccumulatedGDD,\n",
    "         'SowingDate': (['latitude', 'longitude'], xr.where(AccumulatedGDD > 0, np.datetime64(SowingDate), np.datetime64('NaT')).data),\n",
    "         'EndDate': (['latitude', 'longitude'], xr.where(AccumulatedGDD > 0, np.datetime64(EndDate), np.datetime64('NaT')).data)},\n",
    "        coords={'latitude': TmeanDataset['latitude'], 'longitude': TmeanDataset['longitude'],'time':[YearInfo]} # Construct Output Dataset\n",
    "    )\n",
    "    OutputDataset['SowingDate'].attrs.pop('units', None) # \n",
    "    OutputDataset.to_netcdf(f'{OutputFolder}/AccumulatedGDD_{SowingDate}_{EndDate}.nc')\n",
    "\n",
    "    TmeanDataset_MeanCycle = xr.Dataset(\n",
    "        {'Tmean_Cycle': TmeanDataset_MeanCycle,\n",
    "         'SowingDate': (['latitude', 'longitude'], xr.where(AccumulatedGDD > 0, np.datetime64(SowingDate), np.datetime64('NaT')).data),\n",
    "         'EndDate': (['latitude', 'longitude'], xr.where(AccumulatedGDD > 0, np.datetime64(EndDate), np.datetime64('NaT')).data)},\n",
    "        coords={'latitude': TmeanDataset['latitude'], 'longitude': TmeanDataset['longitude'],'time':[YearInfo]} \n",
    "    )\n",
    "    \n",
    "    return OutputDataset, TmeanDataset_MeanCycle\n",
    "\n",
    "def EstimateHeadingDate(WheaterDataset, SowingDate):    \n",
    "    TmeanDataset = WheaterDataset['Tmean'] # Get Mean Temperature Dataset \n",
    "    DateIndex = np.where(TmeanDataset['time'] == np.datetime64(SowingDate))[0][0] # Get Sowing Date Time Index\n",
    "    EndIndex = np.where(TmeanDataset['time'] <= np.datetime64(pd.to_datetime(TmeanDataset['time'].values[DateIndex]) + pd.DateOffset(months=10)))[0][-1] # Get 10 Months After Sowing Date Time Index\n",
    "\n",
    "    AccumulatedGDD = xr.zeros_like(TmeanDataset.isel(time=0)) # Initialize Empty Array To Store AccumulatedGDD\n",
    "    PhaseDateset = xr.zeros_like(TmeanDataset.isel(time=0), dtype=int) # Initialize Empty Array To Store Wheat Phase\n",
    "    DaysToReachHeading = xr.full_like(AccumulatedGDD, np.nan) # Initialize Empty Array To Store Number Of Days Until Antese Is Reached\n",
    "    DaysToReachMaturity = xr.full_like(AccumulatedGDD, np.nan)# Initialize Empty Array To Store Number Of Days Until Maturity Is Reached\n",
    "    DaysToEmergence = xr.full_like(AccumulatedGDD, np.nan) # Initialize Empty Array To Store Number Of Days Until Antese Is Reached\n",
    "\n",
    "    PhasesDict = [{'TempBase': 0, 'Threshold': 90},\n",
    "                  {'TempBase': 0, 'Threshold': 1131},\n",
    "                  {'TempBase': 0, 'Threshold': 2144}]\n",
    "    \n",
    "    for i in range(DateIndex, EndIndex):\n",
    "        TmeanData = TmeanDataset.isel(time=i) # Get Mean Temperature DataArray According to Date\n",
    "        gdd = CalculateGDD(TmeanData, 0) \n",
    "        StopMask = AccumulatedGDD >= PhasesDict[2]['Threshold'] # Update Mask For Pixels That Have Reached Antese  \n",
    "        AccumulatedGDD = xr.where(StopMask, AccumulatedGDD, AccumulatedGDD + gdd) # Update AccumulatedGDD Array\n",
    "        \n",
    "        for p in range(len(PhasesDict)):\n",
    "            PhaseMask = (PhaseDateset == p) & (AccumulatedGDD >= PhasesDict[p]['Threshold']) # Create And Update Mask For Each Phase\n",
    "            if PhaseMask.any():\n",
    "                PhaseDateset = xr.where(PhaseMask, p + 1, PhaseDateset) # Update Phases Array\n",
    "                PhaseDateset = xr.where(PhaseDateset >= len(PhasesDict), len(PhasesDict) - 1, PhaseDateset) # Limit Pixel Phase Update to Antese\n",
    "        \n",
    "        EmergenceMask = (AccumulatedGDD >= PhasesDict[0]['Threshold']) & (np.isnan(DaysToEmergence))\n",
    "        DaysToEmergence = xr.where(EmergenceMask, i - DateIndex, DaysToEmergence)\n",
    "\n",
    "        ReachedHeadingMask = (AccumulatedGDD >= PhasesDict[1]['Threshold']) & (np.isnan(DaysToReachHeading))\n",
    "        DaysToReachHeading = xr.where(ReachedHeadingMask, i - DateIndex, DaysToReachHeading)\n",
    "\n",
    "        ReachedMaturityMask = (AccumulatedGDD >= PhasesDict[2]['Threshold']) & (np.isnan(DaysToReachMaturity))\n",
    "        DaysToReachMaturity = xr.where(ReachedMaturityMask, i - DateIndex, DaysToReachMaturity)\n",
    "\n",
    "    YearInfo = pd.to_datetime(TmeanData['time'].values).year # Store Year Information\n",
    "    OutputDataset = xr.Dataset(\n",
    "        {'AccumulatedGDD': AccumulatedGDD,\n",
    "         'DaysToReachHeading': DaysToReachHeading,\n",
    "         'DaysToReachMaturity': DaysToReachMaturity,\n",
    "         'DaysToEmergence': DaysToEmergence,\n",
    "         'SowingDate': (['latitude', 'longitude'], xr.where(AccumulatedGDD > 0, np.datetime64(pd.to_datetime(SowingDate)), np.datetime64('NaT')).data),\n",
    "         'EmergenceDate': xr.where(AccumulatedGDD > 0, pd.to_datetime(SowingDate) + DaysToEmergence.astype(\"timedelta64[D]\"), np.datetime64('NaT')),\n",
    "         'HeadingDate': xr.where(AccumulatedGDD > 0, pd.to_datetime(SowingDate) + DaysToReachHeading.astype(\"timedelta64[D]\"), np.datetime64('NaT')),\n",
    "         'MaturityDate': xr.where(AccumulatedGDD > 0, pd.to_datetime(SowingDate) + DaysToReachMaturity.astype(\"timedelta64[D]\"), np.datetime64('NaT'))},\n",
    "        coords={'latitude': TmeanDataset['latitude'], 'longitude': TmeanDataset['longitude'],'time':[YearInfo]} # Construct Output Dataset\n",
    "    )\n",
    "    OutputDataset['SowingDate'].attrs.pop('units', None)\n",
    "    \n",
    "    return OutputDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Varaibles Declaration -----------------------------------------------\n",
    "BaseFolder = Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenological Phases Experimental Input Data (Embrapa Boletim Pre-Process) -----------------------------------------------\n",
    "DatesDict = {\n",
    "    2021:{'LengthHeading_0':['03-18'], 'LengthHeading_1':['03-31']},\n",
    "    2020:{'LengthHeading_0':['03-13'], 'LengthHeading_1':['04-06']},\n",
    "    2019:{'LengthHeading_0':['03-12'], 'LengthHeading_1':['04-03']},\n",
    "    2018:{'LengthHeading_0':['03-09'], 'LengthHeading_1':['03-27']},\n",
    "    2016:{'LengthHeading_0':['03-18'], 'LengthHeading_1':['04-06']}\n",
    "}\n",
    "map_0 = {year: v.get('LengthHeading_0', [None])[0] for year, v in DatesDict.items()}\n",
    "map_1 = {year: v.get('LengthHeading_1', [None])[0] for year, v in DatesDict.items()}\n",
    "TrialsDf = pd.read_csv(f\"{BaseFolder}/InputData/BoletimEmprabaDateEstimation.csv\", header=None)\n",
    "TrialsDf.columns = ['Year','Lengths']\n",
    "TrialsDf['Cultivars'] = TrialsDf['Lengths'].str.split(' ').str[0:2].apply(lambda x: \"\".join(x))\n",
    "TrialsDf['LengthHeading_0'] = TrialsDf['Lengths'].str.split(' ').str[-4].astype(int)\n",
    "TrialsDf['LengthHeading_1'] = TrialsDf['Lengths'].str.split(' ').str[-3].astype(int)\n",
    "TrialsDf['LengthMaturity_0'] = TrialsDf['Lengths'].str.split(' ').str[-2].astype(int)\n",
    "TrialsDf['LengthMaturity_1'] = TrialsDf['Lengths'].str.split(' ').str[-1].astype(int)\n",
    "TrialsDf = TrialsDf.drop(columns=['Lengths'])\n",
    "TrialsDf['SowingDate_0'] = TrialsDf['Year'].map(map_0)\n",
    "TrialsDf['SowingDate_0'] = TrialsDf['Year'].astype(str) +'-' + TrialsDf['SowingDate_0'].astype(str)\n",
    "TrialsDf['SowingDate_0'] = pd.to_datetime(TrialsDf['SowingDate_0'])\n",
    "TrialsDf['SowingDate_1'] = TrialsDf['Year'].map(map_1)\n",
    "TrialsDf['SowingDate_1'] = TrialsDf['Year'].astype(str) +'-' + TrialsDf['SowingDate_1'].astype(str)\n",
    "TrialsDf['SowingDate_1'] = pd.to_datetime(TrialsDf['SowingDate_1'])\n",
    "TrialsDf['HeadingDate_0'] = TrialsDf['SowingDate_0'] + pd.to_timedelta(TrialsDf['LengthHeading_0'], unit='D')\n",
    "TrialsDf['HeadingDate_1'] = TrialsDf['SowingDate_1'] + pd.to_timedelta(TrialsDf['LengthHeading_1'], unit='D')\n",
    "TrialsDf['MaturityDate_0'] = TrialsDf['SowingDate_0'] + pd.to_timedelta(TrialsDf['LengthMaturity_0'], unit='D')\n",
    "TrialsDf['MaturityDate_1'] = TrialsDf['SowingDate_1'] + pd.to_timedelta(TrialsDf['LengthMaturity_1'], unit='D')\n",
    "\n",
    "def melt_suffixes_to_long(df, id_vars=None):\n",
    "    if id_vars is None:\n",
    "        id_vars = ['Year', 'Cultivars']\n",
    "\n",
    "    df2 = df.copy()\n",
    "    pattern = re.compile(r'(.+)_([0-9]+)$')\n",
    "    suffixed = [c for c in df2.columns if pattern.match(c)]\n",
    "    melted = df2.melt(id_vars=id_vars, value_vars=suffixed,\n",
    "                      var_name='var_rep', value_name='value')\n",
    "    melted[['base', 'rep']] = melted['var_rep'].str.rsplit('_', n=1, expand=True)\n",
    "    long = (melted\n",
    "            .pivot_table(index=id_vars + ['rep'],\n",
    "                         columns='base',\n",
    "                         values='value',\n",
    "                         aggfunc='first') \n",
    "            .reset_index())\n",
    "    long['rep'] = long['rep'].astype(int)\n",
    "    long.columns.name = None\n",
    "\n",
    "    return long\n",
    "\n",
    "TrialsDf = pd.read_csv(f\"{BaseFolder}/InputData/BoletimEmprabaDateEstimation.csv\", sep=';')\n",
    "TrialsDf = melt_suffixes_to_long(TrialsDf, id_vars=['Year','Cultivars'])\n",
    "TrialsDf = TrialsDf.sort_values(by=['Year', 'Cultivars'])\n",
    "TrialsDf['Local'] = 'Uberaba'\n",
    "TrialsDf = TrialsDf.rename(columns={'LengthHeading': 'DaysToHeading', 'LengthMaturity': 'DaysToMaturity'})\n",
    "TrialsDf = TrialsDf[['Local','Cultivars', 'Year', 'SowingDate', 'HeadingDate', 'MaturityDate', 'DaysToHeading', 'DaysToMaturity']]\n",
    "TrialsDf.to_csv(f\"{BaseFolder}/InputData/BoletimEmprabaDateEstimation.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenological Phases Experimental Input Data ================================\n",
    "# Boletim Embrapa ------------------------------------------------------------\n",
    "# Heading --------------------------------------------------------------------\n",
    "TrialsDf = pd.read_csv(f\"{BaseFolder}/InputData/BoletimEmprabaDateEstimation.csv\", sep=';')\n",
    "date_pairs = (\n",
    "    TrialsDf[['SowingDate', 'MaturityDate']]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .apply(tuple, axis=1)\n",
    "    .tolist()\n",
    ")\n",
    "WheaterDataset = xr.open_dataset(f\"{BaseFolder}/InputData/XavierDataInput.nc\")\n",
    "AccumulatedGddFullDataset = []\n",
    "MeanTempCycleFullDataset = []\n",
    "for SowingDate, HeadingDate in tqdm(date_pairs):\n",
    "    Dataset, MeanTempCycle = CalculateAccumulatedGDD(WheaterDataset, SowingDate, HeadingDate, f\"{BaseFolder}/OutputData\")\n",
    "    AccumulatedGddFullDataset.append(Dataset)\n",
    "    MeanTempCycleFullDataset.append(MeanTempCycle)\n",
    "AccumulatedGddFullDataset = xr.concat(AccumulatedGddFullDataset, dim='time')\n",
    "MeanTempCycleFullDataset = xr.concat(MeanTempCycleFullDataset, dim='time')\n",
    "\n",
    "# Municipalitie extraction -----------------------------------------------------\n",
    "MunCoords = gpd.read_file(f\"{BaseFolder}/InputData/BR_Municipios_2022.shp\")\n",
    "MunCoords = MunCoords[(MunCoords['SIGLA_UF'].isin(['MG'])) & (MunCoords['NM_MUN'].isin(['Uberaba']))]\n",
    "MunCoords['geometry'] = MunCoords.geometry.centroid\n",
    "MunCoords['Latitude'] = MunCoords.geometry.y\n",
    "MunCoords['Longitude'] = MunCoords.geometry.x\n",
    "\n",
    "GddToHeadingDf = []\n",
    "TmeanCycleDf = []\n",
    "for idx, Mun in MunCoords.iterrows():\n",
    "    val = AccumulatedGddFullDataset.sel(latitude=Mun['Latitude'], longitude=Mun['Longitude'], method='nearest').to_dataframe().reset_index()\n",
    "    val['MUN'] = Mun['NM_MUN']\n",
    "    GddToHeadingDf.append(val)\n",
    "    val = MeanTempCycleFullDataset.sel(latitude=Mun['Latitude'], longitude=Mun['Longitude'], method='nearest').to_dataframe().reset_index()\n",
    "    val['MUN'] = Mun['NM_MUN']\n",
    "    TmeanCycleDf.append(val)\n",
    "GddToHeadingDf = pd.concat(GddToHeadingDf)\n",
    "TmeanCycleDf = pd.concat(TmeanCycleDf)\n",
    "GddToHeadingDf = GddToHeadingDf.merge(TmeanCycleDf[['SowingDate', 'EndDate', 'MUN', 'Tmean_Cycle']], on=['SowingDate', 'EndDate', 'MUN'])\n",
    "\n",
    "# Merging ---------------------------------------------------------\n",
    "df1 = TrialsDf.copy()\n",
    "df2 = GddToHeadingDf.copy()\n",
    "\n",
    "df1['SowingDate'] = pd.to_datetime(df1['SowingDate']).dt.normalize()\n",
    "df1['HeadingDate'] = pd.to_datetime(df1['HeadingDate']).dt.normalize()\n",
    "df1['MaturityDate'] = pd.to_datetime(df1['MaturityDate']).dt.normalize()\n",
    "\n",
    "df2['SowingDate'] = pd.to_datetime(df2['SowingDate']).dt.normalize()\n",
    "df2['EndDate']     = pd.to_datetime(df2['EndDate']).dt.normalize()\n",
    "\n",
    "df2_map = (\n",
    "    df2\n",
    "    .groupby(['SowingDate','EndDate','MUN'], as_index=False)\n",
    "    [['AccumulatedGDD', 'Tmean_Cycle']]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "df_merged = df1.merge(\n",
    "    df2_map,\n",
    "    left_on=['SowingDate','MaturityDate','Local'],\n",
    "    right_on=['SowingDate','EndDate','MUN'],\n",
    "    how='left'\n",
    ").drop(columns=['EndDate','MUN'])\n",
    "df_merged = df_merged.rename(columns={'AccumulatedGDD':'GDDToMaturity'})\n",
    "df_merged = df_merged[['Local', 'Year', 'Cultivars', 'SowingDate', 'MaturityDate', 'GDDToMaturity', 'DaysToMaturity', 'Tmean_Cycle']]\n",
    "df_merged.columns = ['site', 'year', 'cultivar', 'sowing_date', 'maturity_date', 'GDD_maturity', 'days_to_maturity', 'mean_temp_cycle']\n",
    "df_merged.to_csv(f\"{BaseFolder}/InputData/BoletimEmprabaMaturityPhenologicalEstimation_Input.csv\", sep=';', index=False)\n",
    "\n",
    "# Recorbe ======================================================================\n",
    "# Heading =====================================================================\n",
    "TrialsDf = pd.read_csv(f\"{BaseFolder}/InputData/RECORBE - brusone - Página1.csv\")\n",
    "TrialsDf['SowingDate'] = pd.to_datetime(TrialsDf['semeadura']).dt.strftime('%Y-%m-%d')\n",
    "TrialsDf['HeadingDate'] = pd.to_datetime(TrialsDf['espigamento']).dt.strftime('%Y-%m-%d')\n",
    "TrialsDf['DaysToHeading'] =  TrialsDf['HD']\n",
    "TrialsDf['MUN'] =  TrialsDf['local']\n",
    "TrialsDf = TrialsDf[TrialsDf['MUN'].isin(['Lavras', 'São Gotardo', 'Uberaba', 'Planaltina'])]\n",
    "date_pairs = (\n",
    "    TrialsDf[['SowingDate', 'HeadingDate']]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .apply(tuple, axis=1)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "WheaterDataset = xr.open_dataset(f\"{BaseFolder}/InputData/Roi_Above_700_NasaPower_2024_2025.nc\")\n",
    "AccumulatedGddFullDataset = []\n",
    "MeanTempCycleFullDataset = []\n",
    "for SowingDate, HeadingDate in tqdm(date_pairs):\n",
    "    Dataset, MeanTempCycle = CalculateAccumulatedGDD(WheaterDataset, SowingDate, HeadingDate, f\"{BaseFolder}/OutputData\")\n",
    "    AccumulatedGddFullDataset.append(Dataset)\n",
    "    MeanTempCycleFullDataset.append(MeanTempCycle)\n",
    "AccumulatedGddFullDataset = xr.concat(AccumulatedGddFullDataset, dim='time')\n",
    "MeanTempCycleFullDataset = xr.concat(MeanTempCycleFullDataset, dim='time')\n",
    "\n",
    "\n",
    "# Municipalitie extraction -----------------------------------------------------\n",
    "MunCoords = gpd.read_file(f\"{BaseFolder}/InputData/BR_Municipios_2022.shp\")\n",
    "MunCoords = MunCoords[(MunCoords['SIGLA_UF'].isin(['MG'])) & (MunCoords['NM_MUN'].isin(['Lavras', 'São Gotardo', 'Uberaba', 'Planaltina']))]\n",
    "MunCoords['geometry'] = MunCoords.geometry.centroid\n",
    "MunCoords['Latitude'] = MunCoords.geometry.y\n",
    "MunCoords['Longitude'] = MunCoords.geometry.x\n",
    "\n",
    "GddToHeadingDf = []\n",
    "TmeanCycleDf = []\n",
    "for idx, Mun in MunCoords.iterrows():\n",
    "    val = AccumulatedGddFullDataset.sel(latitude=Mun['Latitude'], longitude=Mun['Longitude'], method='nearest').to_dataframe().reset_index()\n",
    "    val['MUN'] = Mun['NM_MUN']\n",
    "    GddToHeadingDf.append(val)\n",
    "    val = MeanTempCycleFullDataset.sel(latitude=Mun['Latitude'], longitude=Mun['Longitude'], method='nearest').to_dataframe().reset_index()\n",
    "    val['MUN'] = Mun['NM_MUN']\n",
    "    TmeanCycleDf.append(val)\n",
    "GddToHeadingDf = pd.concat(GddToHeadingDf)\n",
    "TmeanCycleDf = pd.concat(TmeanCycleDf)\n",
    "GddToHeadingDf = GddToHeadingDf.merge(TmeanCycleDf[['SowingDate', 'EndDate', 'MUN', 'Tmean_Cycle']], on=['SowingDate', 'EndDate', 'MUN'])\n",
    "\n",
    "# Merging ---------------------------------------------------------\n",
    "df1 = TrialsDf.copy()\n",
    "df2 = GddToHeadingDf.copy()\n",
    "\n",
    "df1['SowingDate'] = pd.to_datetime(df1['SowingDate']).dt.normalize()\n",
    "df1['HeadingDate'] = pd.to_datetime(df1['HeadingDate']).dt.normalize()\n",
    "\n",
    "df2['SowingDate'] = pd.to_datetime(df2['SowingDate']).dt.normalize()\n",
    "df2['EndDate']     = pd.to_datetime(df2['EndDate']).dt.normalize()\n",
    "\n",
    "df2_map = (\n",
    "    df2\n",
    "    .groupby(['SowingDate','EndDate','MUN'], as_index=False)\n",
    "    [['AccumulatedGDD', 'Tmean_Cycle']]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "df_merged = df1.merge(\n",
    "    df2_map,\n",
    "    left_on=['SowingDate','HeadingDate','local'],\n",
    "    right_on=['SowingDate','EndDate','MUN'],\n",
    "    how='left'\n",
    ")\n",
    "df_merged = df_merged.rename(columns={'AccumulatedGDD':'GDDToHeading'})\n",
    "df_merged = df_merged[['local', 'ano', 'cultivar', 'SowingDate', 'HeadingDate', 'GDDToHeading', 'DaysToHeading', 'Tmean_Cycle']]\n",
    "df_merged.columns = ['site', 'year', 'cultivar', 'sowing_date', 'heading_date', 'GDD_heading', 'days_to_heading', 'mean_temp_cycle']\n",
    "df_merged.to_csv(f\"{BaseFolder}/InputData/RecorbePhenologicalEstimation_Input.csv\", sep=';', index=False)\n",
    "\n",
    "# Patos de Minas ======================================================================\n",
    "# Heading =====================================================================\n",
    "# Patos de Minas Trials Validation --------------------------------------------\n",
    "TrialsDf = pd.read_csv(f\"{BaseFolder}/InputData/DadosPatosDeMinas.csv\")\n",
    "TrialsDf = TrialsDf[TrialsDf['cultivar']!='BRS264']\n",
    "TrialsDf['SowingDate'] = pd.to_datetime(TrialsDf['sowing_date']).dt.strftime('%Y-%m-%d')\n",
    "TrialsDf['HeadingDate'] = pd.to_datetime(TrialsDf['heading_date']).dt.strftime('%Y-%m-%d')\n",
    "TrialsDf['DaysToHeading'] = TrialsDf['heading_days'] \n",
    "TrialsDf['MUN'] = 'Patos de Minas'\n",
    "TrialsDf = TrialsDf[['MUN', 'year','cultivar', 'SowingDate', 'HeadingDate', 'DaysToHeading']]\n",
    "\n",
    "date_pairs = (\n",
    "    TrialsDf[['SowingDate', 'HeadingDate']]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .apply(tuple, axis=1)\n",
    "    .tolist()\n",
    ")\n",
    "WheaterDataset = xr.open_dataset(f\"{BaseFolder}/InputData/XavierDataInput.nc\")\n",
    "AccumulatedGddFullDataset = []\n",
    "MeanTempCycleFullDataset = []\n",
    "for SowingDate, HeadingDate in tqdm(date_pairs):\n",
    "    Dataset, MeanTempCycle = CalculateAccumulatedGDD(WheaterDataset, SowingDate, HeadingDate, f\"{BaseFolder}/OutputData\")\n",
    "    AccumulatedGddFullDataset.append(Dataset)\n",
    "    MeanTempCycleFullDataset.append(MeanTempCycle)\n",
    "AccumulatedGddFullDataset = xr.concat(AccumulatedGddFullDataset, dim='time')\n",
    "MeanTempCycleFullDataset = xr.concat(MeanTempCycleFullDataset, dim='time')\n",
    "\n",
    "# Municipalitie extraction -----------------------------------------------------\n",
    "MunCoords = gpd.read_file(\"D:/Igor_Masters/Auxiliar/BR_Municipios_2022.shp\")\n",
    "MunCoords = MunCoords[(MunCoords['SIGLA_UF'].isin(['MG'])) & (MunCoords['NM_MUN'].isin(['Patos de Minas']))]\n",
    "MunCoords['geometry'] = MunCoords.geometry.centroid\n",
    "MunCoords['Latitude'] = MunCoords.geometry.y\n",
    "MunCoords['Longitude'] = MunCoords.geometry.x\n",
    "\n",
    "GddToHeadingDf = []\n",
    "TmeanCycleDf = []\n",
    "for idx, Mun in MunCoords.iterrows():\n",
    "    val = AccumulatedGddFullDataset.sel(latitude=Mun['Latitude'], longitude=Mun['Longitude'], method='nearest').to_dataframe().reset_index()\n",
    "    val['MUN'] = Mun['NM_MUN']\n",
    "    GddToHeadingDf.append(val)\n",
    "    val = MeanTempCycleFullDataset.sel(latitude=Mun['Latitude'], longitude=Mun['Longitude'], method='nearest').to_dataframe().reset_index()\n",
    "    val['MUN'] = Mun['NM_MUN']\n",
    "    TmeanCycleDf.append(val)\n",
    "GddToHeadingDf = pd.concat(GddToHeadingDf)\n",
    "TmeanCycleDf = pd.concat(TmeanCycleDf)\n",
    "GddToHeadingDf = GddToHeadingDf.merge(TmeanCycleDf[['SowingDate', 'EndDate', 'MUN', 'Tmean_Cycle']], on=['SowingDate', 'EndDate', 'MUN'])\n",
    "\n",
    "# Merging ---------------------------------------------------------\n",
    "df1 = TrialsDf.copy()\n",
    "df2 = GddToHeadingDf.copy()\n",
    "\n",
    "df1['SowingDate'] = pd.to_datetime(df1['SowingDate']).dt.normalize()\n",
    "df1['HeadingDate'] = pd.to_datetime(df1['HeadingDate']).dt.normalize()\n",
    "\n",
    "df2['SowingDate'] = pd.to_datetime(df2['SowingDate']).dt.normalize()\n",
    "df2['EndDate']     = pd.to_datetime(df2['EndDate']).dt.normalize()\n",
    "\n",
    "df2_map = (\n",
    "    df2\n",
    "    .groupby(['SowingDate','EndDate','MUN'], as_index=False)\n",
    "    [['AccumulatedGDD', 'Tmean_Cycle']]\n",
    "    .mean()   # use mean if duplicates; change to first() if you prefer\n",
    ")\n",
    "\n",
    "df_merged = df1.merge(\n",
    "    df2_map,\n",
    "    left_on=['SowingDate','HeadingDate','MUN'],\n",
    "    right_on=['SowingDate','EndDate','MUN'],\n",
    "    how='left'\n",
    ")\n",
    "df_merged = df_merged.rename(columns={'AccumulatedGDD':'GDDToHeading'})\n",
    "df_merged = df_merged[['MUN', 'year', 'cultivar', 'SowingDate', 'HeadingDate', 'GDDToHeading', 'DaysToHeading', 'Tmean_Cycle']]\n",
    "df_merged.columns = ['site', 'year', 'cultivar', 'sowing_date', 'heading_date', 'GDD_heading', 'days_to_heading', 'mean_temp_cycle']\n",
    "df_merged.to_csv(f\"{BaseFolder}/InputData/PatosDeMinasPhenologicalEstimation_Input.csv\", sep=';', index=False)\n",
    "\n",
    "df0 = pd.read_csv(f\"{BaseFolder}/InputData/BoletimEmprabaPhenologicalEstimation_Input.csv\", sep=';')\n",
    "df1 = pd.read_csv(f\"{BaseFolder}/InputData/RecorbePhenologicalEstimation_Input.csv\", sep=';')\n",
    "df2 = pd.read_csv(f\"{BaseFolder}/InputData/PatosDeMinasPhenologicalEstimation_Input.csv\", sep=';')\n",
    "df2 = pd.concat([df0, df1, df2])\n",
    "df2 = df2.dropna(subset=['heading_date'])\n",
    "df2.to_csv(f\"{BaseFolder}/InputData/TrialsPhenologicalEstimation_Input.csv\", sep=';', index=False)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32258d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenological estimation validation ------------------------------------------------\n",
    "# Data Input \n",
    "Df1 = pd.read_csv(f\"{BaseFolder}/InputData/BoletimEmprabaDateEstimation.csv\", sep=';')\n",
    "Df1 = Df1.rename(columns={'Local':'MUN', 'SowingDate': 'SowingDate', 'HeadingDate':'HeadingDate', 'DaysToHeading': 'DaysToHeading','Cultivars':'Cultivar', 'MaturityDate':'MaturityDate', 'DaysToMaturity': 'DaysToMaturity'})\n",
    "Df1 = Df1[['MUN', 'Cultivar', 'SowingDate', 'HeadingDate', 'DaysToHeading', 'MaturityDate', 'DaysToMaturity']]\n",
    "Df1['SowingDate'] = pd.to_datetime(Df1['SowingDate'], errors='coerce').dt.tz_localize(None)\n",
    "Df1['HeadingDate'] = pd.to_datetime(Df1['HeadingDate'], errors='coerce').dt.tz_localize(None)\n",
    "Df1['MaturityDate'] = pd.to_datetime(Df1['MaturityDate'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "Df2 = pd.read_csv(f\"{BaseFolder}/InputData/DadosPatosDeMinas.csv\")\n",
    "Df2['MUN'] = 'Patos de Minas'\n",
    "Df2 = Df2.rename(columns={'sowing_date': 'SowingDate', 'heading_date':'HeadingDate', 'heading_days': 'DaysToHeading','cultivar':'Cultivar'})\n",
    "Df2 = Df2[['MUN', 'Cultivar', 'SowingDate', 'HeadingDate', 'DaysToHeading']]\n",
    "Df2['SowingDate'] = pd.to_datetime(Df2['SowingDate'], errors='coerce').dt.tz_localize(None)\n",
    "Df2['HeadingDate'] = pd.to_datetime(Df2['HeadingDate'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "TrialsDf = pd.concat([Df1,Df2])\n",
    "TrialsDf['DaysToHeading'] = (TrialsDf['HeadingDate'] - TrialsDf['SowingDate']).dt.days\n",
    "TrialsDf['DaysToMaturity'] = (TrialsDf['MaturityDate'] - TrialsDf['SowingDate']).dt.days\n",
    "TrialsDf['SowingDate'] = pd.to_datetime(TrialsDf['SowingDate']).dt.strftime('%Y-%m-%d')\n",
    "TrialsDf['HeadingDate'] = pd.to_datetime(TrialsDf['HeadingDate']).dt.strftime('%Y-%m-%d')\n",
    "TrialsDf['MaturityDate'] = pd.to_datetime(TrialsDf['MaturityDate']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Heading and Maturity date estimation\n",
    "WheaterDataset = xr.open_dataset(f\"{BaseFolder}/InputData/XavierDataInput.nc\")\n",
    "for SowingDate in tqdm(TrialsDf['SowingDate'].unique()):\n",
    "    HeadingDateDataset = EstimateHeadingDate(WheaterDataset, SowingDate)\n",
    "    HeadingDateDataset.to_netcdf(f\"{BaseFolder}/OutputData/Validation_HeandingDates_{SowingDate}.nc\")\n",
    "WheaterDataset.close()\n",
    "\n",
    "# Municipalitie extraction -----------------------------------------------------\n",
    "MunCoords = gpd.read_file(f\"{BaseFolder}/InputData/BR_Municipios_2022.shp\")\n",
    "MunCoords = MunCoords[(MunCoords['SIGLA_UF'].isin(['MG'])) & (MunCoords['NM_MUN'].isin(['Uberaba', 'Patos de Minas']))]\n",
    "MunCoords['geometry'] = MunCoords.geometry.centroid\n",
    "MunCoords['Latitude'] = MunCoords.geometry.y\n",
    "MunCoords['Longitude'] = MunCoords.geometry.x\n",
    "\n",
    "HeadingDatesFullDataset = []\n",
    "TimeIdList = []\n",
    "FilePathList = sorted(gl.glob(f\"{BaseFolder}/OutputData/Validation_HeandingDates*.nc\"))\n",
    "for FilePath in tqdm(FilePathList):\n",
    "    Dataset = xr.open_dataset(FilePath)\n",
    "    TimeIdList.append(FilePath.split('\\\\')[-1].split('_')[-1].split('.')[0])\n",
    "    HeadingDatesFullDataset.append(Dataset)\n",
    "HeadingDatesFullDataset = xr.concat(HeadingDatesFullDataset, dim='time')\n",
    "HeadingDatesFullDataset = HeadingDatesFullDataset.assign_coords(time=TimeIdList)\n",
    "Dataset = None\n",
    "\n",
    "HeadingDatesDf = []\n",
    "for idx, Mun in MunCoords.iterrows():\n",
    "    val = HeadingDatesFullDataset.sel(latitude=Mun['Latitude'], longitude=Mun['Longitude'], method='nearest').to_dataframe().reset_index()\n",
    "    val['MUN'] = Mun['NM_MUN']\n",
    "    HeadingDatesDf.append(val)\n",
    "HeadingDatesDf = pd.concat(HeadingDatesDf)\n",
    "HeadingDatesDf = HeadingDatesDf[['time', 'SowingDate', 'MUN', 'DaysToReachHeading', 'DaysToReachMaturity', 'HeadingDate', 'MaturityDate', 'EmergenceDate', 'DaysToEmergence', 'AccumulatedGDD']]\n",
    "HeadingDatesDf = HeadingDatesDf.sort_values(by=['SowingDate', 'time'])\n",
    "HeadingDatesDf['SowingDate'] = pd.to_datetime(HeadingDatesDf['SowingDate']).dt.strftime('%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
